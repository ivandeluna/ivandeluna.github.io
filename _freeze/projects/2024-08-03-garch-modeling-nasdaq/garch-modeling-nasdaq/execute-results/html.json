{
  "hash": "210b760ca1054af6ee9b45d38a162352",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"GARCH Modeling of Nasdaq 100 Futures\"\ndescription: \"GARCH modeling using NASDAQ 100 Futures and EDA.\"\nauthor: \"Iv√°n de Luna-Aldape\"\ndate: \"8/3/2024\"\ncategories:\n  - econometrics\n  - forecasting\n  - machine-learning\n  - tutorial\nexecute:\n  freeze: true\n---\n\n\n\nIn this post we will generate a basic GARCH(1,1) model applied to NASDAQ 100 future\nprices. The main objetive is to understand the basics of modeling such time series\ngiven that they met certain conditions, such as heteroskedasticity.\n\nThe Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model is a widely used time series analysis technique for modeling the volatility of financial data. It was first introduced by Bollerslev in 1986 as an extension of the earlier ARCH (Autoregressive Conditional Heteroskedasticity) model proposed by Engle in 1982.\n\nThe key idea behind GARCH modeling is that the variance of the error term in a time series model is not constant, but rather varies over time ina predictable way. This time-varying volatility is captured through the specification of the conditional variance equation, which models the variance as a function of past squared errors and past variances.\n\nMatematically, the GARCH(p,q) model can be expressed as:\n\n\n$y_t = \\mu + \\epsilon_t$\n\n$\\epsilon_t = \\sqrt{h_t} z_t$\n\n$h_t = \\omega + \\sum_{i=1}^p \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^q \\beta_j h_{t-j}$\n\nwhere:\n\n- $y_t$ is the time series of interest\n- $\\mu$ is the conditional mean\n- $\\epsilon_t$ is the error term\n- $h_t$ is the conditional variance\n- $z_t$ is a white noise process with zero mean and unit variance\n- $\\omega, \\alpha_i, \\beta_j$ are the model parameters to be estimated\n\nGARCH modeling offers several advantages over traditional time series analysis techniques:\n\n1. **Capturing Volatility Clustering**: GARCH models are able to capture the phenomenon of volatility clustering, where periods of high volatility tend to be followed by periods of high volatility, and periods of low volatility tend to be followed by periods of low volatility.\n2. **Improved Forecasting Accuracy**: by modeling the time-varying variance, GARCH models can provide more accurate forecasts of future volatility compared to models that assume constant variance.\n3. **Risk Management**: GARCH models can be used to estimate the Value-at-Risk (VaR) and other risk measures, which are important for financial risk management.\n4. **Flexibility**: GARCH models can be extenden in various ways, such as incorporating asymmetric effects (EGARCH) or long-memory effects (FIGARCH), to better capture the characteristics of the data.\n\n### Disadvantages and Limitations\n\nWhile GARCH modelling is a powerful tool, it also has some limitaitons and drawbacks:\n\n1. **Complexity**: GARCH models involve the estimation of multiple parameters, which can be computationally intensive, especially for high-frequency data or models with many lags.\n2. **Sensitivity to Model Assumptions**: GARCH models rely on specific assumptions, such as the distribution of the error terms. Violations of these assumptions can lead to biased or inefficient parameter estimates.\n3. **Difficulty in Interpreting Parameters**: The interpretation of the GARCH model parameters can be challenging, as they represent the complex dynamics of the conditional variance process.\n4. **Potential for Misspecification**: if the underlying data-generating process is not well-captured by the GARCH model, the model may produce biased or inaccurate results.\n\nIn this posts we will explore a basic EDA and workflow regarding GARCH modeling.\n\n\n\n\n\n\n\n## Exploratory Data Analysis\n\nFirst we download the NASDAQ 100 futures data and prepare it for the initial analysis:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download Nasdaq 100 futures data\ngetSymbols(\"NQ=F\", src=\"yahoo\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"NQ=F\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract adjusted closing prices\nprices <- Cl(`NQ=F`)\n\n# Calculate log returns\nreturns <- diff(log(prices))\n\n# Remove NA values\nreturns <- returns[!is.na(returns)]\n\n# Plot the returns\nggplot(data.frame(Date = index(returns), Returns = as.numeric(returns)), \n       aes(x = Date, y = Returns)) +\n  geom_line() +\n  theme_minimal() + \n  labs(title = \"NASDAQ 100 Futures log returns\", x = \"Date\", y = \"Log Returns\")\n```\n\n::: {.cell-output-display}\n![](garch-modeling-nasdaq_files/figure-html/download-data-1.png){width=672}\n:::\n:::\n\n\n\nAfter downloading the required data, we calculated log returns and generated a plot.\n\nLog returns are commonly used in financial modeling because they're additive over time and tend to be more normally distributed than simple returns, which also helps \"flatten\" possible outliers that may interfere with the model fitting part.\n\n## Preliminary Statistical Test\n\nBefore fitting a GARCH model, we need to check if our data exhibits characteristics that make a GARCH model appropriate. We'll perform several statistical tests:\n\n### Test for stationarity\n\nThe Augmented Dickey-Fuller test checks for stationarity. A p-value less than 0.05 suggests the series is stationary, which is a requirements for GARCH modeling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadf_test <- adf.test(returns)\nprint(adf_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  returns\nDickey-Fuller = -16.481, Lag order = 16, p-value = 0.01\nalternative hypothesis: stationary\n```\n\n\n:::\n:::\n\n\n\n### Test for Serial Correlation\n\nThe Ljung-Box test checks for serial correlation. A low p-value suggests the presence of serial correlation, which might be addressed by including an ARMA component in our GARCH model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlb_test <- Box.test(returns, lag = 10, type = \"Ljung-Box\")\nprint(lb_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBox-Ljung test\n\ndata:  returns\nX-squared = 71.585, df = 10, p-value = 2.189e-11\n```\n\n\n:::\n:::\n\n\n\n### Test for Heteroskedasticity\n\nThe ARCH LM test checks for the presence of ARCH effects (heteroskedasticity). A low p-value indicates the presence of ARCH effects, suggesting that a GARCH model might be appropriate.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\narch_test <- ArchTest(returns, lags = 5)\nprint(arch_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  returns\nChi-squared = 956.41, df = 5, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n### Test for Normality\n\nThe Jarque-Bera test checks for normality. A low p-value indicates non-normal distribution, which is common in financial returns and often addressed by using a Student's t-distribution for the GARCH model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njb_test <- jarque.bera.test(returns)\nprint(jb_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tJarque Bera Test\n\ndata:  returns\nX-squared = 13137, df = 2, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n### Descriptive Statistics\n\nThe descriptive statistics provide additional insights into the distribution of returns, including skewness and kurtosis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndesc_stats <- c(mean = mean(returns),\n                sd = sd(returns),\n                skewness = skewness(returns),\n                kurtosis = kurtosis(returns))\nprint(desc_stats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         mean            sd      skewness      kurtosis \n 0.0005375851  0.0141310429 -0.3253572664  8.2800525073 \n```\n\n\n:::\n:::\n\n\n\n\n## GARCH Model Fitting\n\nBased on the results of our preliminary tests, we'll now fit a GARCH model to our data.\n\nHere, we've specified a GARCH(1,1) model with an ARMA(1,1) mean model and a Student's t-distribution for the errors. The summary() function provides detailed information about the fitted model, including parameter estimates and various diagnostic statistics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify GARCH model\nspec <- ugarchspec(variance.model = list(model = \"sGARCH\",\n                                         garchOrder = c(1,1)),\n                   mean.model = list(armaOrder = c(1,1)),\n                   distribution.model = \"std\")\n\n# Fit the model\nfit <- ugarchfit(spec, returns)\n```\n:::\n\n\n\n### Model Diagnostics\n\nAfter fitting the GARCH model, we should check if it has adequately captured the volatility dynamics of our data.\n\nAs these test show no significant serial correlation (p-value > 0.05), it suggest that the GARCH model has adequately captured the volatility dynamics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract standardized residuals\nstd_resid <- residuals(fit, standardize = TRUE)\n\n# Ljung-Box test on standardized residuals\nprint(\"Ljung-Box Test on Standardized Residuals:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Ljung-Box Test on Standardized Residuals:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Box.test(std_resid, lag = 10, type = \"Ljung-Box\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBox-Ljung test\n\ndata:  std_resid\nX-squared = 7.6433, df = 10, p-value = 0.6636\n```\n\n\n:::\n:::\n\n\n\nNow we run the diagnostic on squared standardized residuals, in which we obtain a good model indicating that there is no serial autocorrelation within our model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ljung-Box test on squared standardized residuals\nprint(\"Ljung-Box Test on Squared Standardized Residuals:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Ljung-Box Test on Squared Standardized Residuals:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(Box.test(std_resid^2, lag = 10, type = \"Ljung-Box\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBox-Ljung test\n\ndata:  std_resid^2\nX-squared = 5.9434, df = 10, p-value = 0.82\n```\n\n\n:::\n:::\n\n\n\nand create a plot to visualize our model on standardized residuals:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot standardized residuals\nggplot(data.frame(Date = index(returns), Residuals = as.numeric(std_resid)), aes(x = Date, y = Residuals)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Standardized Residuals\", x = \"Date\", y = \"Standardized Residuals\")\n```\n\n::: {.cell-output-display}\n![](garch-modeling-nasdaq_files/figure-html/garch-plot-res-1.png){width=672}\n:::\n:::\n\n\n\n\n## Forecasting Volatility\n\nLet's use our fitted GARCH model to forecast future volatility, by estimating the next 10 periods.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Forecast volatility\nforecast <- ugarchforecast(fit, n.ahead = 10)\nplot(forecast, which = 1)\n```\n\n::: {.cell-output-display}\n![](garch-modeling-nasdaq_files/figure-html/garch-forecast-1.png){width=672}\n:::\n:::\n\n\n\nFinally, we calculate the Value at Risk (VaR) based on our GARCH model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVaR <- quantile(fit@fit$residuals, 0.05)\nprint(paste(\"5% Value at Risk:\", VaR))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5% Value at Risk: -0.0241682999576284\"\n```\n\n\n:::\n:::\n\n\n\nthe 5% VaR represents the loss that we would expect to be exceeded only 5% of the time, based on our GARCH model.\n\n## Conclusion\n\nGARCH models are powerful tools for modeling financial time series, particularly when dealing with volatility clustering and heteroskedasticity. However, it's important to remember that all models are simplifications of reality, and careful interpretation and validation are always necessary.\n\n",
    "supporting": [
      "garch-modeling-nasdaq_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}