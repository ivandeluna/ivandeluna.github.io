{
  "hash": "065d87dd7f22736cdfc8bf9cce09c06e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Energy Price Forecasting Model\"\ndescription: \"Energy price forecasting model using AutoARIMA and model training for class example.\"\nauthor: \"Iv√°n de Luna-Aldape\"\ndate: \"7/23/2024\"\ncategories: \n  - econometrics\n  - forecasting\n  - machine-learning\n  - tutorial\nexecute:\n  freeze: auto\n---\n\n::: {.cell inclue='false'}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo= TRUE)\n```\n:::\n\n\nLoad required libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(lubridate)\n```\n:::\n\n\n\n## Download data\n\nIn this section, we'll download the historical price data for crude oil futures:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndownload_data <- function(symbol, start_date, end_date){\n  getSymbols(symbol, from = start_date, to = end_date, auto.assign = FALSE)\n}\n\n# Set parameters\nsymbol = \"CL=F\"\nstart_date = \"2020-01-01\"\nend_date = \"2023-12-31\"\n\n# Download data\ndata <- download_data(symbol, start_date, end_date)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: CL=F contains missing values. Some functions will not work if objects\ncontain missing values in the middle of the series. Consider using na.omit(),\nna.approx(), na.fill(), etc to remove or replace them.\n```\n\n\n:::\n:::\n\n\n\nDownladed data containd an index, which is in date format but must be adapted to time series, also contains prices in open, high, low and close data, volume which informs about the quantity traded and adjusted close prices.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Dataset summary:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDataset summary:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(summary(data))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Index              CL=F.Open        CL=F.High         CL=F.Low     \n Min.   :2020-01-02   Min.   :-14.00   Min.   : 13.69   Min.   :-40.32  \n 1st Qu.:2020-12-30   1st Qu.: 53.35   1st Qu.: 53.84   1st Qu.: 52.60  \n Median :2021-12-30   Median : 72.97   Median : 73.95   Median : 71.66  \n Mean   :2021-12-31   Mean   : 69.83   Mean   : 71.22   Mean   : 68.30  \n 3rd Qu.:2022-12-29   3rd Qu.: 83.22   3rd Qu.: 84.55   3rd Qu.: 81.81  \n Max.   :2023-12-29   Max.   :124.66   Max.   :130.50   Max.   :120.79  \n                      NA's   :1        NA's   :1        NA's   :1       \n   CL=F.Close      CL=F.Volume      CL=F.Adjusted   \n Min.   :-37.63   Min.   :      0   Min.   :-37.63  \n 1st Qu.: 53.34   1st Qu.: 287602   1st Qu.: 53.34  \n Median : 72.87   Median : 352450   Median : 72.87  \n Mean   : 69.77   Mean   : 378186   Mean   : 69.77  \n 3rd Qu.: 83.13   3rd Qu.: 436951   3rd Qu.: 83.13  \n Max.   :123.70   Max.   :2288230   Max.   :123.70  \n NA's   :1        NA's   :1         NA's   :1       \n```\n\n\n:::\n:::\n\n\nWe can also check if the time period that was downloaded is the one we specified\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"\\nTime period covered:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTime period covered:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Start date:\", as.Date(index(data)[1]), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart date: 18263 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"End date:\", as.Date(index(data)[nrow(data)]),\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEnd date: 19720 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total number of trading days:\", nrow(data),\"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal number of trading days: 1007 \n```\n\n\n:::\n:::\n\n\n\n\n## Preprocess data\nNow, let's process the data by extracting the closing prices and ensuring we have a continous daily time series:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreprocess_data <- function(data){\n  # Extract closing prices and convert to time series\n  close_prices <- as.numeric(data[,4])\n  dates <- index(data)\n  ts_data <- xts(close_prices, order.by = dates)\n  \n  # Ensure daily frequency and forward fill missing values\n  daily_data <- merge(ts_data, xts(, seq(start(ts_data), \n                                         end(ts_data), \n                                         by=\"day\")))\n  daily_data <- na.locf(daily_data)\n  \n  return(daily_data)\n}\n\nprocessed_data <- preprocess_data(data)\n```\n:::\n\n\n\nWe can take a look at our data by ploting the time series:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(Date = index(processed_data), \n                  Price = as.numeric(processed_data)), \n       aes(x = Date, y = Price)) +\n  geom_line() + \n  labs(title = \"Crude oil Futures Closing Prices\",\n       x = \"Date\",\n       y = \"Price (USD)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](energy-price-forecasting-model_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nCalculate and display some statistics\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"\\nBasic statistics of closing prices:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBasic statistics of closing prices:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(summary(as.numeric(processed_data)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n -37.63   53.34   72.91   69.86   83.19  123.70 \n```\n\n\n:::\n:::\n\n\nThe graph shows the daily closing prices of crude oil futures over the specified time period. We can observe serevail intersting details:\n\n1. A sharp drop in prices in early 2020, likely due to the COVID-19 pandeminc.\n2. A gradual recovery and upward trend from mid-2020 to mid-2022.\n3. Some volatility and a slight downward trend in the later part of 2022 and 2023.\n\nThese patterns and the overall volatility will be challenging for our forecasting model to capture.\n\n## Split data\n\nWe'll now split our data into training and testing sets:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit_data <- function(data, test_size = 0.2){\n  split_point <- floor(nrow(data) * (1 - test_size))\n  train <- data[1:split_point, ]\n  test <- data[(split_point + 1):nrow(data), ]\n  return(list(train = train, test = test))\n}\n\nsplit <- split_data(processed_data)\ntrain <- split$train\ntest <- split$test\n\ncat(\"Training set size:\", nrow(train), \"days\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining set size: 1166 days\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Test set size:\", nrow(test), \"days\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest set size: 292 days\n```\n\n\n:::\n:::\n\n\n\nWe've split the data so that 80% is used for training and 20% for testing. This allows us to train our model on a \nsubstantial amount of historical data while still having a significant portion for evaluating its performance.\n\n## Train SARIMA Model\n\nNow, let's train a SARIMA (Seasonal AutoRegressive Integrated Moving Average) model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_sarima <- function(data){\n  # Automatically select the best SARIMA model\n  model <- auto.arima(data)\n  return(model)\n}\n\nmodel <- train_sarima(train)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: data \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.3158\ns.e.   0.0293\n\nsigma^2 = 7.066:  log likelihood = -2791.57\nAIC=5587.14   AICc=5587.15   BIC=5597.26\n\nTraining set error measures:\n                     ME   RMSE      MAE       MPE     MAPE     MASE       ACF1\nTraining set 0.01931691 2.6559 1.228565 0.4895984 2.340853 1.131177 0.01242817\n```\n\n\n:::\n:::\n\n\nSARIMA is a popular model for time series forecasting, with the following properties:\n\n1. Seasonal component: it can capture both seasonal and non-seasonal patterns in the data.\n2. Autoregressive (AR): It uses past values to predict future values.\n3. Integrated (I): It can make the time series stationary by differencing.\n4. Moving Average (MA): It uses past forecast erros in the prediction equation.\n\nThe `auto.arima()` function automatically selects the best SARIMA model based on the AIC (Akaike Information Criterion). The model summary shows:\n\n- The selected ARIMA order (p,d,q): (0, 1, 1)\n- Coefficients in the model: which is an ma1 of -0.3158\n- Measures of fit like AIC, BIC, and log-likelihood\n\nThis automated approach saves time in model selection, but it's always good to validate the results and potentially try manual parameter tuning if needed.\n\n## Make predictions\n\nLet's use our trained model to make predictions:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_predictions <- function(model, n_periods){\n  forecast(model,  h = n_periods)\n}\n\npredictions <- make_predictions(model, nrow(test))\n```\n:::\n\n\n\nThe `forecast()` function generates pint forecasts as well as prediction intervals. The prediction intervals give us an idea of the uncertainty in our forecasts.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Predictions mean value\\n:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPredictions mean value\n:\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(predictions$mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime Series:\nStart = 1167 \nEnd = 1172 \nFrequency = 1 \n[1] 76.6646 76.6646 76.6646 76.6646 76.6646 76.6646\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Predictions lower values\\n:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPredictions lower values\n:\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(predictions$lower)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime Series:\nStart = 1167 \nEnd = 1172 \nFrequency = 1 \n          80%      95%\n1167 73.25800 71.45466\n1168 72.53698 70.35195\n1169 71.92439 69.41508\n1170 71.38237 68.58613\n1171 70.89102 67.83467\n1172 70.43832 67.14232\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Predictions upper values\\n:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPredictions upper values\n:\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(predictions$upper)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime Series:\nStart = 1167 \nEnd = 1172 \nFrequency = 1 \n          80%      95%\n1167 80.07119 81.87454\n1168 80.79222 82.97725\n1169 81.40481 83.91412\n1170 81.94682 84.74307\n1171 82.43818 85.49453\n1172 82.89088 86.18688\n```\n\n\n:::\n:::\n\n\n\n\n## Evaluate Model\n\nNow, let's evaluate our model's performance:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevaluate_model <- function(actual, predicted){\n  rmse <- sqrt(mean((actual - predicted$mean)^2))\n  mae <- mean(abs(actual - predicted$mean))\n  mape <- mean(abs((actual - predicted$mean) / actual)) * 100\n  return(list(RMSE = rmse, MAE = mae, MAPE = mape))\n}\n\nmetrics <- evaluate_model(test, predictions)\ncat(\"RMSE:\", metrics$RMSE, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRMSE: 6.643713 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAE:\", metrics$MAE, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE: 5.556715 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAPE:\", metrics$MAPE, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAPE: 7.044422 \n```\n\n\n:::\n:::\n\n\nWe are using three common metrics to evaluate our model:\n\n1. Root Mean Square Error (RMSE): Measures the standard deviation of the residuals.\n2. Mean Absolute Error (MAE): Measures the average magnitude of the errors in a set of predictions.\n3. Mean Absolute Percentage Error (MAPE): Measures accuracy as a percentage, giving us an idea of how far the predictions are off on average.\n\nThese metrics give us different perspectives on our model's performance. Lower values indicate better performance.\n\n\n## Plot results\n\nFinally, let's visualize our results:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_results <- function(train, test, forecast){\n  # Combine data\n  all_data <- rbind(train, test)\n  \n  # Create a data frame for ggplot\n  plot_data <- data.frame(\n    Date = index(all_data),\n    Price = as.numeric(all_data),\n    Type = c(rep(\"Train\", nrow(train)), rep(\"Test\", nrow(test)))\n  )\n  \n  forecast_data <- data.frame(\n    Date = index(test),\n    Price = as.numeric(forecast$mean),\n    Type = \"Forecast\"\n  )\n  \n  plot_data <- rbind(plot_data, forecast_data)\n  \n  # Create the plot\n  ggplot(plot_data, aes(x = Date, y = Price, color = Type)) + \n    geom_line() +\n    geom_ribbon(data = forecast_data,\n                aes(ymin = forecast$lower[,\"95%\"],\n                    ymax = forecast$upper[,\"95%\"],\n                    fill = Type),\n                alpha = 0.2) +\n    labs(title = \"Energy Price Forecasting\",\n         x = \"Date\",\n         y = \"Price\") +\n    theme_minimal()\n}\n\nplot_results(train, test, predictions)\n```\n\n::: {.cell-output-display}\n![](energy-price-forecasting-model_files/figure-html/plot_results-1.png){width=1152}\n:::\n:::\n\n\n\nThis plot shows:\n\n- The original training data in blue\n- The actual test data in green\n- Our model's predictions in green\n- The shaded area represents the 95% prediction interval for our forecasts\n",
    "supporting": [
      "energy-price-forecasting-model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}